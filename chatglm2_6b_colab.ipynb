{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymKYHc_j16lF"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/THUDM/ChatGLM2-6B\n",
        "!apt -y install -qq aria2\n",
        "\n",
        "# Download ChatGLM2-6B Models from Huggingface\n",
        "import os\n",
        "model_file_names = [\n",
        "\t'MODEL_LICENSE',\n",
        "\t'README.md',\n",
        "\t'config.json',\n",
        "\t'configuration_chatglm.py',\n",
        "\t'modeling_chatglm.py',\n",
        "\t'pytorch_model.bin.index.json',\n",
        "\t'quantization.py',\n",
        "\t'tokenization_chatglm.py',\n",
        "\t'tokenizer_config.json',\n",
        "\t'pytorch_model-00001-of-00007.bin',\n",
        "\t'pytorch_model-00002-of-00007.bin',\n",
        "\t'pytorch_model-00003-of-00007.bin',\n",
        "\t'pytorch_model-00004-of-00007.bin',\n",
        "\t'pytorch_model-00005-of-00007.bin',\n",
        "\t'pytorch_model-00006-of-00007.bin',\n",
        "\t'pytorch_model-00007-of-00007.bin',\n",
        "\t'tokenizer.model'\n",
        "]\n",
        "import os\n",
        "for fname in model_file_names:\n",
        "  cmd = f\"aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/THUDM/chatglm2-6b/resolve/main/{fname} -d /content/ChatGLM2-6B/models -o {fname}\"\n",
        "  os.system(cmd)\n",
        "\n",
        "# Install dependencies\n",
        "%cd /content/ChatGLM2-6B\n",
        "!pip install -r requirements.txt\n",
        "!pip install gradio\n",
        "\n",
        "# Lanuch the web\n",
        "!sed -i \"s/THUDM\\/chatglm2-6b/\\/content\\/ChatGLM2-6B\\/models/g\" web_demo.py\n",
        "!sed -i \"s/demo.queue().launch(share=False, inbrowser=True)/demo.queue().launch(share=True, inbrowser=True)/g\" web_demo.py\n",
        "!python web_demo.py\n"
      ]
    }
  ]
}